{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import IPython.display as ipd\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from TTS.tts.configs.shared_configs import BaseDatasetConfig\n",
    "from TTS.tts.datasets import load_tts_samples, TTSDataset\n",
    "from TTS.tts.utils.speakers import SpeakerManager\n",
    "from TTS.utils.audio import AudioProcessor\n",
    "\n",
    "from TTS.tts.configs.tacotron2_config import Tacotron2Config\n",
    "from TTS.tts.configs.glow_tts_config import GlowTTSConfig\n",
    "from TTS.tts.models.tacotron2 import Tacotron2\n",
    "from TTS.tts.models.glow_tts import GlowTTS\n",
    "from TTS.tts.utils.text.tokenizer import TTSTokenizer\n",
    "\n",
    "from cl_tts.benchmarks.formatters import vctk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " | > Found 44070 files in /raid/hhemati/Datasets/Speech/CL-TTS/VCTK\n"
     ]
    }
   ],
   "source": [
    "ds_path = \"/raid/hhemati/Datasets/Speech/CL-TTS/VCTK/\"\n",
    "dataset_config = BaseDatasetConfig(\n",
    "    name=\"vctk\",  path=ds_path, meta_file_train=\"metadata.txt\"\n",
    ")\n",
    "train_samples, eval_samples = load_tts_samples(dataset_config, formatter=vctk)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43630\n"
     ]
    }
   ],
   "source": [
    "train_samples\n",
    "current_speakers = [\"vctk_p336\"]\n",
    "train_samples2 = [x for x in train_samples if x[\"speaker_name\"] in current_speakers]\n",
    "print(len(train_samples))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log10\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:20\n",
      " | > fft_size:1024\n",
      " | > power:1.5\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:True\n",
      " | > symmetric_norm:True\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:None\n",
      " | > pitch_fmin:0.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:20.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:True\n",
      " | > trim_db:45\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:10\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n"
     ]
    }
   ],
   "source": [
    "config = Tacotron2Config(\n",
    "    text_cleaner=\"phoneme_cleaners\",\n",
    "    use_phonemes=True,\n",
    "    phoneme_language=\"en-us\",\n",
    "    phoneme_cache_path=os.path.join(ds_path, \"phonemes\"),\n",
    "    use_d_vector_file=True,\n",
    "    d_vector_dim=256,\n",
    ")\n",
    "\n",
    "ap = AudioProcessor.init_from_config(config)\n",
    "tokenizer, config = TTSTokenizer.init_from_config(config)\n",
    "\n",
    "d_vectors_file_path = os.path.join(ds_path, \"speaker_embedding_means.json\")\n",
    "speaker_manager = SpeakerManager(d_vectors_file_path=d_vectors_file_path)\n",
    "\n",
    "model = Tacotron2(config, ap, tokenizer, speaker_manager=speaker_manager)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "samples = train_samples\n",
    "is_eval = False\n",
    "\n",
    "def get_dataset(samples, is_eval):\n",
    "    dataset = TTSDataset(\n",
    "        outputs_per_step=config.r if \"r\" in config else 1,\n",
    "        compute_linear_spec=config.model.lower() == \"tacotron\" or config.compute_linear_spec,\n",
    "        compute_f0=config.get(\"compute_f0\", False),\n",
    "        f0_cache_path=config.get(\"f0_cache_path\", None),\n",
    "        samples=samples,\n",
    "        ap=ap,\n",
    "        return_wav=config.return_wav if \"return_wav\" in config else False,\n",
    "        batch_group_size=0 if is_eval else config.batch_group_size * config.batch_size,\n",
    "        min_text_len=config.min_text_len,\n",
    "        max_text_len=config.max_text_len,\n",
    "        min_audio_len=config.min_audio_len,\n",
    "        max_audio_len=config.max_audio_len,\n",
    "        phoneme_cache_path=config.phoneme_cache_path,\n",
    "        precompute_num_workers=config.precompute_num_workers,\n",
    "        use_noise_augment=False if is_eval else config.use_noise_augment,\n",
    "        verbose=False,\n",
    "        # speaker_id_mapping=speaker_id_mapping,\n",
    "        # d_vector_mapping=d_vector_mapping if config.use_d_vector_file else None,\n",
    "        tokenizer=tokenizer,\n",
    "        start_by_longest=config.start_by_longest,\n",
    "        # language_id_mapping=language_id_mapping,\n",
    "    )\n",
    "\n",
    "    return dataset\n",
    "\n",
    "dataset = get_dataset(train_samples, False)\n",
    "dataset.preprocess_samples()\n",
    "data_loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=False,  # shuffle is done in the dataset.\n",
    "    collate_fn=dataset.collate_fn,\n",
    "    drop_last=False,  # setting this False might cause issues in AMP training.\n",
    "    sampler=None,\n",
    "    num_workers=0,\n",
    "    pin_memory=False,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "{'raw_text': 'I want him to take on Gomez.',\n 'token_ids': array([  4,  64, 130,  25,  44,  16,  22, 130,  10,  64,  15, 130,  22,\n         49, 130,  22,   8,  64,  13, 130,  44,  16, 130,  56,  17,  90,\n         15,  51,  28, 126], dtype=int32),\n 'wav': array([-3.0517578e-05,  3.0517578e-05,  6.1035156e-05, ...,\n         4.5471191e-03,  4.5166016e-03,  4.3334961e-03], dtype=float32),\n 'pitch': None,\n 'attn': None,\n 'item_idx': '/raid/hhemati/Datasets/Speech/CL-TTS/VCTK/wavs/p323/p323_424.wav',\n 'speaker_name': 'vctk_p323',\n 'language_name': '',\n 'wav_file_name': 'p323_424.wav'}"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [],
   "source": [
    "batch = next(iter(data_loader))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [],
   "source": [
    "speaker_embeddings = [model.speaker_manager.get_d_vectors_by_speaker(spk) for spk in batch[\"speaker_names\"]]\n",
    "speaker_embeddings = torch.FloatTensor(speaker_embeddings).squeeze(1)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "data": {
      "text/plain": "Tacotron2(\n  (embedding): Embedding(131, 512, padding_idx=0)\n  (encoder): Encoder(\n    (convolutions): ModuleList(\n      (0): ConvBNBlock(\n        (convolution1d): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n        (batch_normalization): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (dropout): Dropout(p=0.5, inplace=False)\n        (activation): ReLU()\n      )\n      (1): ConvBNBlock(\n        (convolution1d): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n        (batch_normalization): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (dropout): Dropout(p=0.5, inplace=False)\n        (activation): ReLU()\n      )\n      (2): ConvBNBlock(\n        (convolution1d): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n        (batch_normalization): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (dropout): Dropout(p=0.5, inplace=False)\n        (activation): ReLU()\n      )\n    )\n    (lstm): LSTM(512, 256, batch_first=True, bidirectional=True)\n  )\n  (decoder): Decoder(\n    (prenet): Prenet(\n      (linear_layers): ModuleList(\n        (0): Linear(\n          (linear_layer): Linear(in_features=80, out_features=256, bias=False)\n        )\n        (1): Linear(\n          (linear_layer): Linear(in_features=256, out_features=256, bias=False)\n        )\n      )\n    )\n    (attention_rnn): LSTMCell(1024, 1024)\n    (attention): OriginalAttention(\n      (query_layer): Linear(\n        (linear_layer): Linear(in_features=1024, out_features=128, bias=False)\n      )\n      (inputs_layer): Linear(\n        (linear_layer): Linear(in_features=768, out_features=128, bias=False)\n      )\n      (v): Linear(\n        (linear_layer): Linear(in_features=128, out_features=1, bias=True)\n      )\n      (location_layer): LocationLayer(\n        (location_conv1d): Conv1d(2, 32, kernel_size=(31,), stride=(1,), padding=(15,), bias=False)\n        (location_dense): Linear(\n          (linear_layer): Linear(in_features=32, out_features=128, bias=False)\n        )\n      )\n    )\n    (decoder_rnn): LSTMCell(1792, 1024)\n    (linear_projection): Linear(\n      (linear_layer): Linear(in_features=1792, out_features=160, bias=True)\n    )\n    (stopnet): Sequential(\n      (0): Dropout(p=0.1, inplace=False)\n      (1): Linear(\n        (linear_layer): Linear(in_features=1184, out_features=1, bias=True)\n      )\n    )\n  )\n  (postnet): Postnet(\n    (convolutions): ModuleList(\n      (0): ConvBNBlock(\n        (convolution1d): Conv1d(80, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n        (batch_normalization): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (dropout): Dropout(p=0.5, inplace=False)\n        (activation): Tanh()\n      )\n      (1): ConvBNBlock(\n        (convolution1d): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n        (batch_normalization): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (dropout): Dropout(p=0.5, inplace=False)\n        (activation): Tanh()\n      )\n      (2): ConvBNBlock(\n        (convolution1d): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n        (batch_normalization): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (dropout): Dropout(p=0.5, inplace=False)\n        (activation): Tanh()\n      )\n      (3): ConvBNBlock(\n        (convolution1d): Conv1d(512, 512, kernel_size=(5,), stride=(1,), padding=(2,))\n        (batch_normalization): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (dropout): Dropout(p=0.5, inplace=False)\n        (activation): Tanh()\n      )\n      (4): ConvBNBlock(\n        (convolution1d): Conv1d(512, 80, kernel_size=(5,), stride=(1,), padding=(2,))\n        (batch_normalization): BatchNorm1d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (dropout): Dropout(p=0.5, inplace=False)\n        (activation): Identity()\n      )\n    )\n  )\n)"
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"token_id\"] = batch[\"token_id\"].cuda()\n",
    "batch[\"token_id_lengths\"] = batch[\"token_id_lengths\"].cuda()\n",
    "batch[\"mel\"] = batch[\"mel\"].cuda()\n",
    "batch[\"mel_lengths\"] = batch[\"mel_lengths\"].cuda()\n",
    "speaker_embeddings = speaker_embeddings.cuda()\n",
    "model.cuda()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [],
   "source": [
    "model.train()\n",
    "out = model(\n",
    "    batch[\"token_id\"],\n",
    "    batch[\"token_id_lengths\"],\n",
    "    mel_specs=batch[\"mel\"],\n",
    "    mel_lengths=batch[\"mel_lengths\"],\n",
    "    aux_input={\"d_vectors\": speaker_embeddings}\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [
    {
     "data": {
      "text/plain": "{'model_outputs': tensor([[[ 1.4087e+00,  9.6026e-01,  3.3456e+00,  2.2402e+00,  3.4868e+00,\n            1.5307e-01, -3.2522e-03, -1.9621e-01, -7.3938e-02, -9.5912e-01,\n            3.4012e+00, -2.0375e+00, -8.5886e-01, -2.8008e-03, -3.1925e-02,\n            8.3162e-01,  1.0890e-01, -1.3711e-01,  2.9591e+00,  2.2140e+00,\n           -8.8970e-02, -2.9820e+00,  5.0595e-01,  7.5702e-04,  5.1531e-02,\n            1.4500e-01, -1.8699e+00, -6.3906e-02, -5.1753e-02,  1.0715e+00,\n           -1.4882e+00, -3.5094e-02, -2.6576e+00,  2.7956e+00, -9.1014e-02,\n            6.2020e-02, -9.5604e-02, -9.6077e-02, -6.0496e-02,  1.7436e+00,\n           -5.8411e-01,  6.8754e-01,  2.8475e+00,  1.0079e+00,  3.4597e+00,\n           -5.5588e-02, -5.2296e-01, -4.0184e-02, -2.5774e+00, -3.1671e-02,\n            2.4623e+00,  3.3097e+00,  1.0811e-01,  4.5793e-02,  3.3436e+00,\n           -7.7866e-01,  1.5434e-01,  1.7471e-01,  9.7976e-01,  1.1042e+00,\n           -7.9637e-02, -9.7339e-03,  6.8717e-02, -1.5057e+00, -1.2055e-01,\n            1.2292e+00, -3.6001e-04, -2.9991e+00, -1.5864e+00, -2.0162e+00,\n            5.9936e-02,  1.6944e-01, -2.5040e+00, -8.4034e-02,  3.5916e+00,\n           -4.2462e-01,  2.6593e+00,  2.3778e+00,  7.6461e-01,  2.5875e+00],\n          [-2.8858e+00, -2.4297e+00, -1.7866e+00, -2.4452e+00, -1.4965e+00,\n            3.3583e+00,  4.5080e-02, -5.5625e-02,  3.3492e+00, -1.0598e+00,\n           -9.3853e-01,  3.2182e-01, -2.5934e+00,  9.2160e-02, -1.9829e-02,\n            8.3919e-02,  8.6100e-02, -8.7389e-02, -3.5807e-01,  1.5079e+00,\n            2.0071e+00, -6.6173e-01,  2.8565e-02, -2.9821e-02,  1.6988e-02,\n           -3.4280e+00, -2.1922e+00, -2.2944e-01, -1.5891e-01, -2.0329e-02,\n           -2.3757e+00, -1.8223e-01,  3.0031e+00, -1.8629e+00, -1.5194e+00,\n            3.5385e-02, -4.9830e-02,  1.5621e-01,  7.0164e-02, -3.1273e+00,\n            4.7563e-02,  1.2367e-01,  1.1035e+00, -3.2412e+00, -1.1052e-01,\n           -1.2616e+00, -3.0600e+00, -2.4337e+00, -4.0964e-01, -6.2977e-01,\n           -4.0288e-02, -1.8290e+00,  4.2047e-02,  3.2373e+00,  2.1704e-01,\n            7.1736e-02, -3.2531e+00, -1.1410e-01,  2.3245e+00, -3.1696e+00,\n            1.0200e-01, -3.1642e-02,  5.7593e-01,  1.8579e-01,  8.1399e-02,\n            1.2342e-01,  2.7195e+00,  1.5814e+00,  4.9669e-02,  1.7093e+00,\n           -1.4433e-01, -3.2221e+00,  7.4079e-02,  2.4645e-01, -7.9732e-01,\n           -3.0892e+00, -1.0577e-02, -2.4623e+00,  4.0771e-02, -3.0094e+00],\n          [ 2.2539e+00, -1.3991e+00, -6.9487e-03,  1.4072e-02,  9.9651e-02,\n            1.5221e-01, -2.4848e+00, -3.3796e+00, -4.8266e-02,  6.3068e-03,\n           -5.9412e-02,  6.3794e-02,  2.8820e+00, -1.4834e-02, -3.3627e+00,\n            1.7990e-01, -3.3329e+00, -1.3989e-01, -3.0146e-01, -1.3711e-01,\n           -3.3193e+00,  2.4243e-02, -1.2067e-01,  2.4612e-02,  6.1674e-02,\n            1.4331e+00,  2.4724e+00, -1.4659e+00, -4.1531e-02,  1.3219e-01,\n           -3.1707e-03, -3.6544e-02,  1.2003e-01, -1.2036e-01,  3.2127e+00,\n            9.5515e-01,  3.1932e+00, -1.3350e+00, -8.4637e-01,  2.1929e-02,\n           -7.7018e-02,  2.8257e-02, -2.3859e+00,  1.8085e+00,  7.7761e-04,\n           -3.5166e-02, -8.0362e-02, -3.2743e-02,  1.3682e-01,  2.5287e+00,\n           -8.4529e-02, -1.0075e+00,  1.2684e-01, -2.3120e+00, -1.2033e+00,\n            1.0974e+00,  1.6665e-01,  2.8169e+00, -1.2227e-02, -5.0781e-02,\n           -2.0957e+00,  1.5726e+00,  6.8524e-02, -1.7559e-01, -3.3906e+00,\n           -1.5185e-01,  6.5765e-01, -1.0869e-01,  2.5158e-01,  1.1004e-01,\n            6.9404e-02,  1.7348e-01, -1.2691e+00, -9.5237e-02,  1.5169e-01,\n            7.9439e-02,  5.5448e-01, -1.3066e+00, -3.2926e+00, -7.9802e-03],\n          [ 1.2105e-01, -4.3912e-02, -3.5263e-01,  1.6961e+00, -3.4351e-01,\n           -1.9390e+00, -8.2985e-01, -1.4200e-01, -1.4099e+00,  6.3703e-02,\n           -1.3916e+00, -1.2478e+00,  6.2036e-01,  2.3191e+00,  1.1512e+00,\n            1.7177e+00,  1.0616e-01,  1.4541e+00, -2.5898e+00, -2.5528e+00,\n           -1.3642e-02, -5.0478e-02,  3.1515e-02, -1.9503e+00,  1.1985e+00,\n            1.6828e+00,  1.2455e+00, -1.7550e+00, -2.3263e+00, -2.7434e-02,\n            1.1804e+00, -1.8235e-01,  1.8760e-01, -6.4993e-02, -1.6426e+00,\n            2.8223e-02, -8.2916e-01,  1.5901e-01, -2.6476e+00,  1.6775e-03,\n            4.9584e-02,  1.3228e-01,  2.7783e-02,  6.5658e-02, -1.0622e-01,\n            7.3780e-01, -7.7761e-02, -2.3486e-01,  2.1940e-01,  8.1968e-01,\n           -2.9480e-02,  1.0063e-01, -1.8324e+00,  1.2422e-01, -4.7309e-01,\n            2.4222e+00, -1.3038e-01, -3.2444e-01,  6.6466e-02, -1.9544e-01,\n            7.1404e-02, -2.2577e-02, -9.8667e-01, -1.9688e+00,  1.2221e+00,\n            1.0979e-01, -2.8248e+00, -3.6246e-02,  5.1240e-02,  8.5175e-02,\n           -3.5620e-01,  2.2938e-02,  1.1402e+00, -1.2601e+00,  6.0725e-02,\n           -2.9930e-02, -2.9660e+00,  1.5117e+00,  1.9328e+00,  5.4910e-01]]],\n        device='cuda:0'),\n 'decoder_outputs': tensor([[[ 4.7148e-02, -5.5488e-02,  8.9644e-03, -5.8112e-03,  9.9610e-02,\n            1.5307e-01, -3.2522e-03, -1.9621e-01, -5.1243e-02,  6.9222e-03,\n           -5.2030e-02,  7.0969e-02,  6.9041e-02, -2.8008e-03, -3.1925e-02,\n            1.8172e-01,  1.0890e-01, -1.3711e-01, -1.0425e-01, -1.4224e-01,\n           -8.8970e-02,  2.7843e-02, -1.6048e-02,  7.5702e-04,  5.1531e-02,\n            1.4500e-01, -7.9380e-02, -6.3906e-02, -5.1753e-02,  1.3542e-01,\n           -8.4751e-03, -3.5094e-02,  1.2288e-01, -1.0119e-01, -9.1014e-02,\n            6.2020e-02,  1.1513e-02, -9.6077e-02, -6.0496e-02,  2.7463e-02,\n           -8.2068e-02,  2.9361e-02,  2.5121e-01, -9.2597e-02,  1.1560e-02,\n           -5.5588e-02, -9.3168e-02, -4.0184e-02,  1.3965e-01, -3.1671e-02,\n           -7.2040e-02, -2.8055e-02,  1.0811e-01,  4.5793e-02, -7.4785e-02,\n           -1.4073e-01,  1.5434e-01,  1.7471e-01, -2.5204e-02, -3.5137e-02,\n           -7.9637e-02, -9.7339e-03,  6.8717e-02, -1.7918e-01, -1.2055e-01,\n           -1.3639e-01, -3.6001e-04, -1.2642e-01,  1.9978e-02,  8.6297e-02,\n            5.9936e-02,  1.6944e-01, -2.3095e-02, -8.4034e-02,  1.5962e-01,\n            7.4031e-02,  2.5238e-02, -3.6024e-02,  7.1368e-02,  3.7466e-02],\n          [ 1.2060e-01, -4.9327e-02,  1.9129e-01,  3.6748e-02,  1.3240e-01,\n            1.5977e-02, -9.4188e-02, -5.5625e-02,  7.9699e-02,  6.1180e-02,\n            1.3567e-03,  4.8747e-02, -2.2007e-02,  9.2160e-02, -1.9829e-02,\n            8.3919e-02,  8.6100e-02, -8.7389e-02, -4.2992e-02,  1.3163e-02,\n           -8.2756e-02, -4.9137e-02,  2.8565e-02, -2.9821e-02,  1.6988e-02,\n           -9.6567e-02, -8.7120e-02, -8.3319e-03, -1.5891e-01, -2.0329e-02,\n           -3.2455e-02, -1.8223e-01,  1.7952e-01, -4.9923e-02, -2.7304e-03,\n            3.5385e-02, -4.9830e-02,  1.5621e-01,  7.0164e-02,  1.4612e-03,\n            4.7563e-02,  1.2367e-01,  9.3452e-03,  8.2624e-02, -1.1052e-01,\n           -9.3760e-02, -8.2151e-02,  1.1550e-02, -9.4971e-03, -6.8513e-02,\n           -4.0288e-02,  1.0123e-01,  4.2047e-02,  1.1049e-01,  2.1704e-01,\n            7.1736e-02, -1.4101e-01, -1.1410e-01,  7.0134e-02, -2.1108e-02,\n            1.0200e-01, -3.1642e-02,  3.4438e-03,  4.5825e-02, -4.0848e-02,\n            1.2342e-01,  5.8832e-02, -3.2107e-02,  4.9669e-02,  6.5156e-02,\n           -1.4433e-01,  4.6257e-03,  7.4079e-02,  2.4645e-01,  5.5357e-02,\n           -4.4280e-02, -1.0577e-02,  9.3754e-02,  4.0771e-02,  2.5160e-02],\n          [ 6.1422e-02, -3.5615e-02, -6.9487e-03,  1.4072e-02,  9.9651e-02,\n            1.5221e-01, -1.2081e-02, -1.8809e-01, -4.8266e-02,  6.3068e-03,\n           -5.9412e-02,  6.3794e-02,  3.6287e-02, -1.4834e-02, -3.9568e-02,\n            1.7990e-01,  1.1761e-01, -1.3989e-01, -9.7112e-02, -1.3711e-01,\n           -8.4373e-02,  2.4243e-02, -2.5218e-03,  2.4612e-02,  6.1674e-02,\n            1.5098e-01, -9.7200e-02, -9.6727e-02, -4.1531e-02,  1.3219e-01,\n           -3.1707e-03, -3.6544e-02,  1.2003e-01, -1.2036e-01, -1.0047e-01,\n            4.2972e-02,  9.7001e-03, -1.1432e-01, -4.9070e-02,  2.1929e-02,\n           -7.7018e-02,  2.8257e-02,  2.5001e-01, -9.9596e-02,  7.7761e-04,\n           -3.5166e-02, -8.0362e-02, -3.2743e-02,  1.3682e-01, -1.6495e-02,\n           -8.4529e-02, -3.7541e-02,  1.2684e-01,  4.6574e-02, -9.0688e-02,\n           -1.2121e-01,  1.6665e-01,  1.7185e-01, -1.2227e-02, -5.0781e-02,\n           -8.0250e-02,  5.6713e-03,  6.8524e-02, -1.7559e-01, -1.0603e-01,\n           -1.5185e-01,  5.7857e-03, -1.0869e-01,  1.6595e-02,  1.1004e-01,\n            6.9404e-02,  1.7348e-01, -1.4669e-02, -9.5237e-02,  1.5169e-01,\n            7.9439e-02,  4.7165e-03, -3.0631e-02,  6.8916e-02,  4.1255e-02],\n          [ 1.2105e-01, -4.3912e-02,  2.0421e-01,  3.4404e-02,  1.3129e-01,\n            2.6875e-02, -1.0677e-01, -4.8875e-02,  7.9529e-02,  6.3703e-02,\n           -7.6703e-03,  4.7592e-02, -3.3159e-02,  1.1133e-01, -2.9598e-02,\n            8.3026e-02,  1.0616e-01, -8.5043e-02, -4.5951e-02,  4.0310e-03,\n           -8.0873e-02, -5.0478e-02,  3.1515e-02, -1.4766e-02,  3.1575e-02,\n           -1.0258e-01, -8.0490e-02, -1.9138e-02, -1.5502e-01, -2.7434e-02,\n           -1.9603e-02, -1.8235e-01,  1.8760e-01, -6.4993e-02,  1.6414e-04,\n            2.8223e-02, -3.9498e-02,  1.5901e-01,  6.9862e-02,  1.6775e-03,\n            4.9584e-02,  1.3228e-01,  2.7783e-02,  6.5658e-02, -1.0622e-01,\n           -9.6882e-02, -7.7761e-02,  2.5648e-02,  2.2652e-03, -9.0648e-02,\n           -2.9480e-02,  1.0063e-01,  4.8849e-02,  1.2422e-01,  2.2317e-01,\n            7.2777e-02, -1.3038e-01, -9.7559e-02,  6.6466e-02, -2.3218e-02,\n            7.1404e-02, -2.2577e-02,  1.7038e-02,  3.7058e-02, -4.6552e-02,\n            1.0979e-01,  5.7441e-02, -3.6246e-02,  5.1240e-02,  8.5175e-02,\n           -1.5700e-01,  2.2938e-02,  7.7017e-02,  2.4697e-01,  6.0725e-02,\n           -2.9930e-02, -1.5671e-02,  9.3518e-02,  2.4635e-02,  1.5298e-02]]],\n        device='cuda:0'),\n 'alignments': tensor([[[0.0322, 0.0252, 0.0214, 0.0281, 0.0366, 0.0386, 0.0305, 0.0341,\n           0.0364, 0.0319, 0.0344, 0.0298, 0.0364, 0.0335, 0.0313, 0.0412,\n           0.0308, 0.0322, 0.0353, 0.0299, 0.0264, 0.0331, 0.0401, 0.0245,\n           0.0221, 0.0258, 0.0304, 0.0311, 0.0285, 0.0342, 0.0273, 0.0270],\n          [0.0321, 0.0254, 0.0216, 0.0283, 0.0367, 0.0385, 0.0307, 0.0343,\n           0.0365, 0.0321, 0.0345, 0.0300, 0.0365, 0.0338, 0.0313, 0.0409,\n           0.0310, 0.0324, 0.0351, 0.0299, 0.0263, 0.0328, 0.0398, 0.0244,\n           0.0219, 0.0258, 0.0301, 0.0308, 0.0284, 0.0339, 0.0273, 0.0271]]],\n        device='cuda:0'),\n 'stop_tokens': tensor([[[0.5124],\n          [0.5047]]], device='cuda:0')}"
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.inference(batch[\"token_id\"][0].unsqueeze(0),\n",
    "                {\"d_vectors\": speaker_embeddings[0].unsqueeze(0)})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [],
   "source": [
    "class MyClass:\n",
    "    def __int__(self):\n",
    "        self.a = 5\n",
    "\n",
    "    def func1(self, x):\n",
    "        x += self.a\n",
    "        return x\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [],
   "source": [
    "mc = MyClass()\n",
    "f = mc.func1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MyClass' object has no attribute 'a'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Input \u001B[0;32mIn [110]\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m5\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Input \u001B[0;32mIn [108]\u001B[0m, in \u001B[0;36mMyClass.func1\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfunc1\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[0;32m----> 6\u001B[0m     x \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43ma\u001B[49m\n\u001B[1;32m      7\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m x\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'MyClass' object has no attribute 'a'"
     ]
    }
   ],
   "source": [
    "f(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}